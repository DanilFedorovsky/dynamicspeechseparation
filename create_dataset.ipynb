{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyroomacoustics as pra\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr: 20000\n",
      "cv: 5000\n",
      "tt: 3000\n",
      "['wsj0/si_tr_s/40n/40na010x.wav', 'wsj0/si_tr_s/01x/01xo031a.wav']\n"
     ]
    }
   ],
   "source": [
    "wsj0path = \"/project/data_asr/wham_dataset/whamr_data/wsj0_raw/\"\n",
    "\n",
    "cv = []\n",
    "with open('mix_2_spk_cv.txt','r') as txt:\n",
    "    out = txt.readline()\n",
    "    while out != \"\":\n",
    "        out = out.split()\n",
    "        cv.append([out[0],out[2]])\n",
    "        out = txt.readline()\n",
    "\n",
    "tr = []\n",
    "with open('mix_2_spk_tr.txt','r') as txt:\n",
    "    out = txt.readline()\n",
    "    while out != \"\":\n",
    "        out = out.split()\n",
    "        tr.append([out[0],out[2]])\n",
    "        out = txt.readline()\n",
    "\n",
    "tt = []\n",
    "with open('mix_2_spk_tt.txt','r') as txt:\n",
    "    out = txt.readline()\n",
    "    while out != \"\":\n",
    "        out = out.split()\n",
    "        tt.append([out[0],out[2]])\n",
    "        out = txt.readline()\n",
    "\n",
    "print(\"tr:\",len(tr))\n",
    "print(\"cv:\",len(cv))\n",
    "print(\"tt:\",len(tt))\n",
    "print(tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40na010x'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr[0][0].split(\"/\")[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_length(a:torch.Tensor,b:torch.Tensor):\n",
    "    len_a = a.shape[1]\n",
    "    len_b = b.shape[1]\n",
    "    if len_a > len_b:\n",
    "        add = len_a - len_b\n",
    "        b = torch.cat([b,torch.zeros(add).unsqueeze(0)],dim=1)\n",
    "    elif len_b > len_a:\n",
    "        add = len_b - len_a\n",
    "        a = torch.cat([a,torch.zeros(add).unsqueeze(0)],dim=1)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREATE_PATH = \"/project/data_asr/CHiME5/data/wsj0-mix2/twoChannelRoom/\"\n",
    "\n",
    "def create_dataset(part: list, subfolder: str):\n",
    "    for line in part:\n",
    "        # Load two audiofiles\n",
    "        wav_a = torchaudio.load(wsj0path+line[0])[0][0]\n",
    "        wav_b = torchaudio.load(wsj0path+line[1])[0][0]\n",
    "\n",
    "        #wav_a, wav_b = same_length(wav_a,wav_b)\n",
    "\n",
    "        # Simulate room and obtain mix / s1 / s2\n",
    "        room = pra.ShoeBox([4,6]) # Or AnechoicRoom \n",
    "        room.add_source([2.5, 4.5], signal=wav_a)\n",
    "        room.add_source([0.5, 3.0], signal=wav_b)\n",
    "\n",
    "        R = pra.linear_2D_array([2, 1.5], 2, 0, 0.1)\n",
    "        room.add_microphone_array(pra.Beamformer(R, room.fs))\n",
    "        \n",
    "        room.simulate()\n",
    "\n",
    "        name_file = line[0].split(\"/\")[-1][:-4] + \"_\" + line[1].split(\"/\")[-1]\n",
    "        room.mic_array.to_wav(\n",
    "            (CREATE_PATH + subfolder + \"mix/\" + name_file),\n",
    "            norm=True,\n",
    "            bitdepth=np.int16,\n",
    "        )\n",
    "        break\n",
    "    # TODO: Korrigiere Sample Rate auf 16k Hz\n",
    "    return \"Done\"\n",
    "\n",
    "create_dataset(cv,\"cv/\")\n",
    "create_dataset(tr,\"tr/\")\n",
    "create_dataset(tt,\"tt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyroomacoustics.room.ShoeBox at 0x7f23dd1de580>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = torchaudio.load(wsj0path+tt[0][0])[0]\n",
    "room = pra.ShoeBox([4,6]) # Or AnechoicRoom \n",
    "room.add_source([2.5, 4.5], signal=audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/project/data_asr/CHiME5/data/wsj0-mix2/2speakers/wav8k/min/tr/mix/\"\n",
    "\n",
    "for file in tqdm(os.listdir(PATH)):\n",
    "    # TWO / 3 SIGNAL SOURCES!!!\n",
    "\n",
    "    fs, audio = wavfile.read(PATH+file)\n",
    "\n",
    "    # Create a 4 by 6 metres shoe box room\n",
    "    room = pra.ShoeBox([4,6]) # Or AnechoicRoom \n",
    "    room.add_source([2.5, 4.5], signal=audio)\n",
    "\n",
    "    # Create a linear array with 2 microphones with angle 0 degrees and inter mic distance 10 cm\n",
    "    R = pra.linear_2D_array([2, 1.5], 1, 0, 0.1)\n",
    "    room.add_microphone_array(pra.Beamformer(R, room.fs))\n",
    "\n",
    "    # Simulate propagation\n",
    "    room.simulate()\n",
    "\n",
    "    room.mic_array.to_wav(\n",
    "        (\"/project/data_asr/CHiME5/data/wsj0-mix2/oneChannelRoom/tr/mix/\" + str(file)),\n",
    "        norm=True,\n",
    "        bitdepth=np.int16,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('beamformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7edcfa7c72349f2a40b8bb9d00f805dd689758e4b70f704e502841c884b714f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
